<!DOCTYPE html>
<html lang="en-us"><head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  






  
  
  
    
    
  





  



  
  

<link rel="stylesheet" href="https://ai-doge.github.io/main.min.css" />


  
<meta name="robots" content="index, follow">
    <meta name="googlebot" content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1">
    <meta name="bingbot" content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1">
  

<title>iOS LLaMa</title>


<meta name="author" content="Ai Doge">

<meta name="description" content="How to Port the LLaMa Model to Run on iOS Devices">
<link rel="canonical" href="https://ai-doge.github.io/posts/llama-ios/">
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="iOS LLaMa">
<meta property="og:description" content="How to Port the LLaMa Model to Run on iOS Devices">
<meta property="og:url" content="https://ai-doge.github.io/posts/llama-ios/">
<meta property="article:published_time" content="2023-09-01T21:21:46-05:00">
  <meta property="article:modified_time" content="2023-09-01T21:21:46-05:00">
  


  <meta name="og:image" content="https://ai-doge.github.io/images/ai-doge.jpg"/>






  <meta name="twitter:site" content="aidogeshow">


  <meta name="twitter:creator" content="aidogeshow">

<meta name="twitter:title" content="iOS LLaMa">
<meta name="twitter:description" content="How to Port the LLaMa Model to Run on iOS Devices">



  <meta name="twitter:card" content="summary_large_image"/>
  <meta name="twitter:image" content="https://ai-doge.github.io/images/ai-doge.jpg"/>





  


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@graph": [
    {
      "@type": "Person",
      "@id": "https://ai-doge.github.io/#/schema/person/1",
      "name": "Ai Doge",
      "url": "https://ai-doge.github.io/",
      "image": {
        "@type": "ImageObject",
        "@id": "https://ai-doge.github.io/#/schema/image/1",
        "url": "https://ai-doge.github.io/images/ai-doge.jpg",
        "width": 453 ,
        "height": 455 ,
        "caption": "Ai Doge"
      }
    },
    {
      "@type": "WebSite",
      "@id": "https://ai-doge.github.io/#/schema/website/1",
      "url": "https://ai-doge.github.io/",
      "name": "ai-doge",
      "description": "Ai-Doge's Blog",
      "publisher": {
        "@id": "https://ai-doge.github.io/#/schema/person/1"
      }
    },
    {
      "@type": "WebPage",
      "@id": "https://ai-doge.github.io/posts/llama-ios/",
      "url": "https://ai-doge.github.io/posts/llama-ios/",
      "name": "Port the LLaMa Model on iOS",
      "description": "How to Port the LLaMa Model to Run on iOS Devices",
      "isPartOf": {
        "@id": "https://ai-doge.github.io/#/schema/website/1"
      },
      "about": {
        "@id": "https://ai-doge.github.io/#/schema/person/1"
      },
      "datePublished": "2023-09-01T21:21:46-05:00",
      "dateModified": "2023-09-01T21:21:46-05:00",
      "breadcrumb": {
        "@id": "https://ai-doge.github.io/posts/llama-ios/#/schema/breadcrumb/1"
      },
      "primaryImageOfPage": {
        "@id": "https://ai-doge.github.io/posts/llama-ios/#/schema/image/2"
      },
      "inLanguage": "en-US",
      "potentialAction": [{
        "@type": "ReadAction", "target": ["https://ai-doge.github.io/posts/llama-ios/"]
      }]
    },
    {
      "@type": "BreadcrumbList",
      "@id": "https://ai-doge.github.io/posts/llama-ios/#/schema/breadcrumb/1",
      "name": "Breadcrumbs",
      "itemListElement": [{
        "@type": "ListItem",
        "position":  1 ,
        "item": {
          "@type": "WebPage",
          "@id": "https://ai-doge.github.io/",
          "url": "https://ai-doge.github.io/",
          "name": "Home"
          }
        },{
        "@type": "ListItem",
        "position":  2 ,
        "item": {
          "@type": "WebPage",
          "@id": "https://ai-doge.github.io/posts/",
          "url": "https://ai-doge.github.io/posts/",
          "name": "Posts"
          }
        },{
        "@type": "ListItem",
        "position":  3 ,
        "item": {
          "@id": "https://ai-doge.github.io/posts/llama-ios/"
          }
        }]
    },
    {
      "@context": "https://schema.org",
      "@graph": [
        {
          "@type": "Article",
          "@id": "https://ai-doge.github.io/#/schema/article/1",
          "headline": "Port the LLaMa Model on iOS",
          "description": "How to Port the LLaMa Model to Run on iOS Devices",
          "isPartOf": {
            "@id": "https://ai-doge.github.io/posts/llama-ios/"
          },
          "mainEntityOfPage": {
            "@id": "https://ai-doge.github.io/posts/llama-ios/"
          },
          "datePublished": "2023-09-01T21:21:46-05:00",
          "dateModified": "2023-09-01T21:21:46-05:00",
          "author": {
            "@id": "https://ai-doge.github.io/#/schema/person/1"
          },          
          "publisher": {
            "@id": "https://ai-doge.github.io/#/schema/person/1"
          },
          "image": {
            "@id": "https://ai-doge.github.io/posts/llama-ios/#/schema/image/2"
          }
        }
      ]
    },{
      "@context": "https://schema.org",
      "@graph": [
        {
          "@type": "ImageObject",
          "@id": "https://ai-doge.github.io/posts/llama-ios/#/schema/image/2",
          "url": "https://ai-doge.github.io/images/ai-doge.jpg",
          "contentUrl": "https://ai-doge.github.io/images/ai-doge.jpg",
          "caption": "Port the LLaMa Model on iOS"
        }
      ]
    }
  ]
}
</script>
  

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">

  

</head><body>
    <header class="container">
  <nav class="main-nav" id="js-navbar">
    <a class="logo" href="https://ai-doge.github.io/">ai-doge</a>
    <ul class="menu" id="js-menu">
      
      
      
      <li class="menu-item">
        <span class="menu-link">Products<span class="drop-icon">▾</span></span>
        <ul class="sub-menu">
          
            <li class="menu-item">
              <a href="/projects/" class="menu-link">Products</a>                  
            </li>
          
            <li class="menu-item">
              <a href="/about/" class="menu-link">About</a>                  
            </li>
          
        </ul>
      </li>
      
      
      
      <li class="menu-item">
        <span class="menu-link">Posts<span class="drop-icon">▾</span></span>
        <ul class="sub-menu">
          
            <li class="menu-item">
              <a href="/posts/" class="menu-link">All Posts</a>                  
            </li>
          
        </ul>
      </li>
      
      
      <li class="menu-item--align">
        <div class="switch">
          <input class="switch-input" type="checkbox" id="themeSwitch">
          <label aria-hidden="true" class="switch-label" for="themeSwitch">On</label>
          <div aria-hidden="true" class="switch-marker"></div>
        </div>
      </li>
    </ul>
    <span class="nav-toggle" id="js-navbar-toggle">
      <svg xmlns="http://www.w3.org/2000/svg" id="Outline" viewBox="0 0 24 24" width="30" height="30" fill="var(--color-contrast-high)"><rect y="11" width="24" height="2" rx="1"/><rect y="4" width="24" height="2" rx="1"/><rect y="18" width="24" height="2" rx="1"/></svg>
    </span>
  </nav>
</header><main class="section">
<div class="container">
  <section class="page-header">
    <h1 class="page-header-title">Port the LLaMa Model on iOS</h1>
    <div class="post-list-meta">
      <div class="post-list-dates">Sep 1, 2023&nbsp;&middot;&nbsp;4 min.</div>
      
      <div class="post-list-categories">
        
          <a href="https://ai-doge.github.io/categories/llm/">LLM</a>
        
          <a href="https://ai-doge.github.io/categories/llama/">LLaMa</a>
        
      </div>
      
      
    </div>
    <p class="page-header-desc">How to Port the LLaMa Model to Run on iOS Devices</p>
    <div class="single-terms">
      
      
      <a class="term" href="https://ai-doge.github.io/tags/llama/">LLaMa</a></li>
      
      <a class="term" href="https://ai-doge.github.io/tags/mpsx/">MPSX</a></li>
      
      <a class="term" href="https://ai-doge.github.io/tags/onnx/">ONNX</a></li>
      
      
    </div>
  </section>
</div>
<div class="single-container-post">
  

  <aside class="toc">
    <div id="js-toc-toggle">
      <h2 class="toc-header">Table of Contents</h2>
      <span class="toc-drop-icon">&blacktriangledown;</span>
    </div>
    <div id="js-toc-contents" class="toc-contents"><nav id="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#part-1-exporting-the-model-to-onnx-format">Part 1: Exporting the Model to ONNX Format</a>
      <ul>
        <li><a href="#the-challenge">The Challenge</a></li>
        <li><a href="#our-solution">Our Solution</a></li>
        <li><a href="#code-changes-for-onnx-export">Code Changes for ONNX Export</a></li>
      </ul>
    </li>
    <li><a href="#part-2-exporting-to-onnx-format-post-pr">Part 2: Exporting to ONNX Format Post-PR</a>
      <ul>
        <li><a href="#the-onnx-export-code">The ONNX Export Code</a></li>
      </ul>
    </li>
    <li><a href="#part-3-running-the-onnx-model-on-ios-devices">Part 3: Running the ONNX Model on iOS Devices</a>
      <ul>
        <li><a href="#utilizing-mpsx-library">Utilizing MPSX Library</a></li>
        <li><a href="#enhancements-to-mpsx">Enhancements to MPSX</a></li>
        <li><a href="#code-snippet-loading-and-running-the-onnx-model">Code Snippet: Loading and Running the ONNX Model</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
  </aside>

  <div class="single-post-contents">
    <div class="single-feature-img">



  

</div>
    <article class="markdown">
        <h1 id="running-baby-llama2-model-on-ios-with-illustrate-llama-app">Running Baby llama2 Model on iOS with Illustrate Llama App<a href="#running-baby-llama2-model-on-ios-with-illustrate-llama-app">
    <svg role="img" aria-labelledby="running-baby-llama2-model-on-ios-with-illustrate-llama-app-IconTitle" fill="var(--color-primary)" height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg">
      <title id="running-baby-llama2-model-on-ios-with-illustrate-llama-app-IconTitle">Link to this heading</title>
      <path d="M0 0h24v24H0z" fill="none"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg>
  </a>
</h1><h2 id="introduction">Introduction<a href="#introduction">
    <svg role="img" aria-labelledby="introduction-IconTitle" fill="var(--color-primary)" height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg">
      <title id="introduction-IconTitle">Link to this heading</title>
      <path d="M0 0h24v24H0z" fill="none"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg>
  </a>
</h2><p>In this blog post, we&rsquo;ll walk through the technical steps involved in running the Baby llama2 model from the <a href="https://github.com/karpathy/llama2.c" target="_blank" rel="noopener">llama2.c GitHub repository</a> on an iOS app called <a href="https://apps.apple.com/us/app/illustrate-llama/id6452017369" target="_blank" rel="noopener">Illustrate Llama</a>. We&rsquo;ll cover the process of exporting the model to ONNX format, integrating it into the iOS app, and the challenges we faced along the way.</p>
<h2 id="part-1-exporting-the-model-to-onnx-format">Part 1: Exporting the Model to ONNX Format<a href="#part-1-exporting-the-model-to-onnx-format">
    <svg role="img" aria-labelledby="part-1-exporting-the-model-to-onnx-format-IconTitle" fill="var(--color-primary)" height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg">
      <title id="part-1-exporting-the-model-to-onnx-format-IconTitle">Link to this heading</title>
      <path d="M0 0h24v24H0z" fill="none"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg>
  </a>
</h2><h3 id="the-challenge">The Challenge<a href="#the-challenge">
    <svg role="img" aria-labelledby="the-challenge-IconTitle" fill="var(--color-primary)" height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg">
      <title id="the-challenge-IconTitle">Link to this heading</title>
      <path d="M0 0h24v24H0z" fill="none"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg>
  </a>
</h3><p>The first step in our journey was to export the pre-trained Baby llama2 model to ONNX format. However, we encountered a roadblock: the llama2.c project did not initially support ONNX export. The primary reason was that ONNX did not support the <code>Complex64</code> data type, which was used in the codebase.</p>
<p>For more context, you can refer to the GitHub issue <a href="https://github.com/karpathy/llama2.c/issues/142" target="_blank" rel="noopener">here</a>.</p>
<h3 id="our-solution">Our Solution<a href="#our-solution">
    <svg role="img" aria-labelledby="our-solution-IconTitle" fill="var(--color-primary)" height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg">
      <title id="our-solution-IconTitle">Link to this heading</title>
      <path d="M0 0h24v24H0z" fill="none"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg>
  </a>
</h3><p>To overcome this challenge, we submitted a Pull Request (<a href="https://github.com/karpathy/llama2.c/pull/103" target="_blank" rel="noopener">PR #103</a>) to the llama2.c repository. The core idea behind the PR was to decompose the operations involving complex numbers into separate operations for the real and imaginary parts.</p>
<h3 id="code-changes-for-onnx-export">Code Changes for ONNX Export<a href="#code-changes-for-onnx-export">
    <svg role="img" aria-labelledby="code-changes-for-onnx-export-IconTitle" fill="var(--color-primary)" height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg">
      <title id="code-changes-for-onnx-export-IconTitle">Link to this heading</title>
      <path d="M0 0h24v24H0z" fill="none"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg>
  </a>
</h3><p>To resolve the issue with the <code>Complex64</code> data type, we made several changes to the codebase. Below are some of the key modifications:</p>
<h4 id="replacing-complex-numbers-with-real-and-imaginary-parts">Replacing Complex Numbers with Real and Imaginary Parts<a href="#replacing-complex-numbers-with-real-and-imaginary-parts">
    <svg role="img" aria-labelledby="replacing-complex-numbers-with-real-and-imaginary-parts-IconTitle" fill="var(--color-primary)" height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg">
      <title id="replacing-complex-numbers-with-real-and-imaginary-parts-IconTitle">Link to this heading</title>
      <path d="M0 0h24v24H0z" fill="none"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg>
  </a>
</h4><p>Originally, the code used complex numbers for certain calculations. We replaced these with separate real and imaginary parts.</p>


  <span class="code-language">python</span><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1</span><span><span style="color:#75715e"># Original code</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2</span><span>freqs_cis <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>polar(torch<span style="color:#f92672">.</span>ones_like(freqs), freqs)  <span style="color:#75715e"># complex64</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4</span><span><span style="color:#75715e"># Modified code</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5</span><span>freqs_cos <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cos(freqs)  <span style="color:#75715e"># real part</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6</span><span>freqs_sin <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>sin(freqs)  <span style="color:#75715e"># imaginary part</span></span></span></code></pre></div>
<h4 id="modifying-the-rotary-embedding-function">Modifying the Rotary Embedding Function<a href="#modifying-the-rotary-embedding-function">
    <svg role="img" aria-labelledby="modifying-the-rotary-embedding-function-IconTitle" fill="var(--color-primary)" height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg">
      <title id="modifying-the-rotary-embedding-function-IconTitle">Link to this heading</title>
      <path d="M0 0h24v24H0z" fill="none"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg>
  </a>
</h4><p>The <code>apply_rotary_emb</code> function was also modified to accommodate the changes.</p>


  <span class="code-language">python</span><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1</span><span><span style="color:#75715e"># Original code</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2</span><span>xq_out <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>view_as_real(xq_ <span style="color:#f92672">*</span> freqs_cis)<span style="color:#f92672">.</span>flatten(<span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3</span><span>xk_out <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>view_as_real(xk_ <span style="color:#f92672">*</span> freqs_cis)<span style="color:#f92672">.</span>flatten(<span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5</span><span><span style="color:#75715e"># Modified code</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6</span><span>xq_out_r <span style="color:#f92672">=</span> xq_r <span style="color:#f92672">*</span> freqs_cos <span style="color:#f92672">-</span> xq_i <span style="color:#f92672">*</span> freqs_sin
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7</span><span>xq_out_i <span style="color:#f92672">=</span> xq_r <span style="color:#f92672">*</span> freqs_sin <span style="color:#f92672">+</span> xq_i <span style="color:#f92672">*</span> freqs_cos
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">8</span><span>xk_out_r <span style="color:#f92672">=</span> xk_r <span style="color:#f92672">*</span> freqs_cos <span style="color:#f92672">-</span> xk_i <span style="color:#f92672">*</span> freqs_sin
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">9</span><span>xk_out_i <span style="color:#f92672">=</span> xk_r <span style="color:#f92672">*</span> freqs_sin <span style="color:#f92672">+</span> xk_i <span style="color:#f92672">*</span> freqs_cos</span></span></code></pre></div>
<h4 id="updating-the-forward-method">Updating the Forward Method<a href="#updating-the-forward-method">
    <svg role="img" aria-labelledby="updating-the-forward-method-IconTitle" fill="var(--color-primary)" height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg">
      <title id="updating-the-forward-method-IconTitle">Link to this heading</title>
      <path d="M0 0h24v24H0z" fill="none"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg>
  </a>
</h4><p>The forward method in various classes was updated to use the new real and imaginary parts.</p>


  <span class="code-language">python</span><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1</span><span><span style="color:#75715e"># Original code</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2</span><span>h <span style="color:#f92672">=</span> layer(h, freqs_cis)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4</span><span><span style="color:#75715e"># Modified code</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5</span><span>h <span style="color:#f92672">=</span> layer(h, freqs_cos, freqs_sin)</span></span></code></pre></div>
<p>By making these changes, we were able to successfully export the Baby llama2 model to ONNX format without any issues related to the <code>Complex64</code> data type.</p>
<h2 id="part-2-exporting-to-onnx-format-post-pr">Part 2: Exporting to ONNX Format Post-PR<a href="#part-2-exporting-to-onnx-format-post-pr">
    <svg role="img" aria-labelledby="part-2-exporting-to-onnx-format-post-pr-IconTitle" fill="var(--color-primary)" height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg">
      <title id="part-2-exporting-to-onnx-format-post-pr-IconTitle">Link to this heading</title>
      <path d="M0 0h24v24H0z" fill="none"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg>
  </a>
</h2><h3 id="the-onnx-export-code">The ONNX Export Code<a href="#the-onnx-export-code">
    <svg role="img" aria-labelledby="the-onnx-export-code-IconTitle" fill="var(--color-primary)" height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg">
      <title id="the-onnx-export-code-IconTitle">Link to this heading</title>
      <path d="M0 0h24v24H0z" fill="none"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg>
  </a>
</h3><p>After successfully merging our Pull Request, we were able to export the Baby llama2 model to ONNX format. Below is the Python code snippet that demonstrates how to perform the export:</p>


  <span class="code-language">python</span><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1</span><span>torch<span style="color:#f92672">.</span>onnx<span style="color:#f92672">.</span>export(model,
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2</span><span>                  torch<span style="color:#f92672">.</span>from_numpy(input),
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3</span><span>                  <span style="color:#e6db74">&#34;./model_128.onnx&#34;</span>,
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4</span><span>                  verbose<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5</span><span>                  input_names<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#34;input&#34;</span>],
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6</span><span>                  output_names<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#34;output&#34;</span>])</span></span></code></pre></div>
<p>In this code snippet:</p>
<ul>
<li><code>model</code>: The pre-trained Baby llama2 model.</li>
<li><code>torch.from_numpy(input)</code>: The input tensor converted from a NumPy array.</li>
<li><code>./model_128.onnx</code>: The path where the exported ONNX model will be saved.</li>
<li><code>verbose=True</code>: Enables verbose output to understand the export process.</li>
<li><code>input_names</code> and <code>output_names</code>: Specifies the names for the input and output nodes in the ONNX graph.</li>
</ul>
<p>By running this code, the model is exported to an ONNX file named <code>model_128.onnx</code>, which can then be integrated into our iOS application.</p>
<h2 id="part-3-running-the-onnx-model-on-ios-devices">Part 3: Running the ONNX Model on iOS Devices<a href="#part-3-running-the-onnx-model-on-ios-devices">
    <svg role="img" aria-labelledby="part-3-running-the-onnx-model-on-ios-devices-IconTitle" fill="var(--color-primary)" height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg">
      <title id="part-3-running-the-onnx-model-on-ios-devices-IconTitle">Link to this heading</title>
      <path d="M0 0h24v24H0z" fill="none"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg>
  </a>
</h2><h3 id="utilizing-mpsx-library">Utilizing MPSX Library<a href="#utilizing-mpsx-library">
    <svg role="img" aria-labelledby="utilizing-mpsx-library-IconTitle" fill="var(--color-primary)" height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg">
      <title id="utilizing-mpsx-library-IconTitle">Link to this heading</title>
      <path d="M0 0h24v24H0z" fill="none"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg>
  </a>
</h3><p>To run the ONNX model on iOS, we leveraged a closed-source modification of the <a href="https://github.com/prisma-ai/MPSX" target="_blank" rel="noopener">MPSX library</a>. MPSX is an excellent open-source project that allows you to load ONNX models on iOS using Swift and perform inference in a straightforward manner.</p>
<h3 id="enhancements-to-mpsx">Enhancements to MPSX<a href="#enhancements-to-mpsx">
    <svg role="img" aria-labelledby="enhancements-to-mpsx-IconTitle" fill="var(--color-primary)" height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg">
      <title id="enhancements-to-mpsx-IconTitle">Link to this heading</title>
      <path d="M0 0h24v24H0z" fill="none"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg>
  </a>
</h3><p>We made extensive enhancements to the MPSX library to support a more comprehensive set of ONNX operators and offer a more flexible way to invoke the model. These modifications enabled us to integrate the ONNX model seamlessly into our iOS application.</p>
<h3 id="code-snippet-loading-and-running-the-onnx-model">Code Snippet: Loading and Running the ONNX Model<a href="#code-snippet-loading-and-running-the-onnx-model">
    <svg role="img" aria-labelledby="code-snippet-loading-and-running-the-onnx-model-IconTitle" fill="var(--color-primary)" height="22" viewBox="0 0 24 24" width="22" xmlns="http://www.w3.org/2000/svg">
      <title id="code-snippet-loading-and-running-the-onnx-model-IconTitle">Link to this heading</title>
      <path d="M0 0h24v24H0z" fill="none"></path>
      <path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path>
    </svg>
  </a>
</h3><p>Below is a Swift code snippet that demonstrates how to load the ONNX model and perform inference:</p>


  <span class="code-language">swift</span><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-swift" data-lang="swift"><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1</span><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">testLlama2_fp32</span>() {
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2</span><span>    <span style="color:#66d9ef">let</span> path = <span style="color:#e6db74">&#34;model_path&#34;</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3</span><span>    <span style="color:#66d9ef">let</span> onnxModel = <span style="color:#66d9ef">try</span>! OnnxModel(path: path <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;/llama2.sim.fp16.onnx&#34;</span>)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5</span><span>    <span style="color:#66d9ef">let</span> inputConfigs = [<span style="color:#e6db74">&#34;input&#34;</span>: OnnxGraphInputConfig(shape: [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">103</span>], type: .int64)]
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6</span><span>    <span style="color:#66d9ef">let</span> outputConfigs = [<span style="color:#e6db74">&#34;output&#34;</span>: OnnxGraphOutputConfig()]
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7</span><span>    <span style="color:#66d9ef">let</span> globalConfig = OnnxGraphGlobalConfig(floatPrecision: .float32)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8</span><span>    <span style="color:#66d9ef">let</span> graphConfig = OnnxGraphConfig(inputConfigs: inputConfigs,
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9</span><span>                                      outputConfigs: outputConfigs,
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10</span><span>                                      globalConfig: globalConfig,
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11</span><span>                                      gradConfig: <span style="color:#66d9ef">nil</span>)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13</span><span>    <span style="color:#66d9ef">let</span> graph = <span style="color:#66d9ef">try</span>! OnnxGraphBuilder().build(onnxModel: onnxModel, config: graphConfig)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14</span><span>    <span style="color:#66d9ef">let</span> input = Tensor.loadFromNpy(path: path <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;/input.npy&#34;</span>)<span style="color:#f92672">!</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15</span><span>  
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16</span><span>    <span style="color:#66d9ef">let</span> output = graph.forward(inputs: [<span style="color:#e6db74">&#34;input&#34;</span>: input], outputs: [<span style="color:#e6db74">&#34;output&#34;</span>])[<span style="color:#e6db74">&#34;output&#34;</span>]<span style="color:#f92672">!</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17</span><span>}</span></span></code></pre></div>
<p>In this code snippet:</p>
<ul>
<li><code>OnnxModel</code>: Class for loading the ONNX model.</li>
<li><code>OnnxGraphInputConfig</code> and <code>OnnxGraphOutputConfig</code>: Classes for configuring the input and output shapes and types.</li>
<li><code>OnnxGraphGlobalConfig</code>: Class for setting global configurations like float precision.</li>
<li><code>OnnxGraphBuilder</code>: Class for building the graph for inference.</li>
<li><code>Tensor.loadFromNpy</code>: Method for loading input data from an NPY file.</li>
</ul>
<p>By running this code, you can perform inference using the ONNX model on your iOS device.</p>

    </article>
    <aside>
      <div class="single-terms">
        
          
          <a class="term" href="https://ai-doge.github.io/tags/llama/">LLaMa</a></li>
          
          <a class="term" href="https://ai-doge.github.io/tags/mpsx/">MPSX</a></li>
          
          <a class="term" href="https://ai-doge.github.io/tags/onnx/">ONNX</a></li>
          
        
      </div>
      
  
  
  

  <section>
    <h2>Share</h2>
    <div class="social-links">
      <ul class="social-icons--share">
        
        
        <a href="https://twitter.com/intent/tweet?url=https%3a%2f%2fai-doge.github.io%2fposts%2fllama-ios%2f&amp;text=Port%20the%20LLaMa%20Model%20on%20iOS" target="_blank" rel="noopener" aria-label="Share on Twitter" class="social-btn twitter">
          <li><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-twitter" width="24" height="24" viewBox="0 0 384 312" fill="var(--color-primary)"><path d="m384 36.9c-14.1 6.3-29.3 10.5-45.2 12.4 16.3-9.7 28.8-25.2 34.6-43.6-15.2 9-32.1 15.6-50 19.1-14.4-15.2-34.9-24.8-57.5-24.8-43.5 0-78.8 35.3-78.8 78.8 0 6.2.7 12.2 2 17.9-65.5-3.3-123.5-34.6-162.4-82.3-6.7 11.6-10.6 25.2-10.6 39.6 0 27.3 13.9 51.4 35 65.6-12.9-.4-25.1-4-35.7-9.9v1c0 38.2 27.2 70 63.2 77.2-6.6 1.8-13.6 2.8-20.8 2.8-5.1 0-10-.5-14.8-1.4 10 31.3 39.1 54.1 73.6 54.7-27 21.1-60.9 33.7-97.8 33.7-6.4 0-12.6-.4-18.8-1.1 34.9 22.4 76.3 35.4 120.8 35.4 144.9 0 224.1-120 224.1-224.1 0-3.4-.1-6.8-.2-10.2 15.4-11.1 28.7-25 39.3-40.8z"/></svg></li>
        </a>
        
        
        
        <a href="https://www.reddit.com/submit?url=https%3a%2f%2fai-doge.github.io%2fposts%2fllama-ios%2f" target="_blank" rel="noopener" aria-label="Share on Reddit" class="social-btn reddit">
          <li><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-reddit" width="24" height="24" viewBox="0 0 24 24" fill="var(--color-primary)"><path d="M24 11.779c0-1.459-1.192-2.645-2.657-2.645-.715 0-1.363.286-1.84.746-1.81-1.191-4.259-1.949-6.971-2.046l1.483-4.669 4.016.941-.006.058c0 1.193.975 2.163 2.174 2.163 1.198 0 2.172-.97 2.172-2.163s-.975-2.164-2.172-2.164c-.92 0-1.704.574-2.021 1.379l-4.329-1.015c-.189-.046-.381.063-.44.249l-1.654 5.207c-2.838.034-5.409.798-7.3 2.025-.474-.438-1.103-.712-1.799-.712-1.465 0-2.656 1.187-2.656 2.646 0 .97.533 1.811 1.317 2.271-.052.282-.086.567-.086.857 0 3.911 4.808 7.093 10.719 7.093s10.72-3.182 10.72-7.093c0-.274-.029-.544-.075-.81.832-.447 1.405-1.312 1.405-2.318zm-17.224 1.816c0-.868.71-1.575 1.582-1.575.872 0 1.581.707 1.581 1.575s-.709 1.574-1.581 1.574-1.582-.706-1.582-1.574zm9.061 4.669c-.797.793-2.048 1.179-3.824 1.179l-.013-.003-.013.003c-1.777 0-3.028-.386-3.824-1.179-.145-.144-.145-.379 0-.523.145-.145.381-.145.526 0 .65.647 1.729.961 3.298.961l.013.003.013-.003c1.569 0 2.648-.315 3.298-.962.145-.145.381-.144.526 0 .145.145.145.379 0 .524zm-.189-3.095c-.872 0-1.581-.706-1.581-1.574 0-.868.709-1.575 1.581-1.575s1.581.707 1.581 1.575-.709 1.574-1.581 1.574z"/></svg></li>
        </a>
        
        
                
        <a href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fai-doge.github.io%2fposts%2fllama-ios%2f" target="_blank" rel="noopener" aria-label="Share on Facebook" class="social-btn facebook">
          <li><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-facebook" width="24" height="24" viewBox="0 0 352 352" fill="var(--color-primary)"><path d="m0 32v288c0 17.5 14.5 32 32 32h288c17.5 0 32-14.5 32-32v-288c0-17.5-14.5-32-32-32h-288c-17.5 0-32 14.5-32 32zm320 0v288h-83v-108h41.5l6-48h-47.5v-31c0-14 3.5-23.5 23.5-23.5h26v-43.5c-4.4-.6-19.8-1.5-37.5-1.5-36.9 0-62 22.2-62 63.5v36h-42v48h42v108h-155v-288z"/></svg></li>
        </a>
        
        
        
        <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fai-doge.github.io%2fposts%2fllama-ios%2f&amp;source=https%3a%2f%2fai-doge.github.io%2fposts%2fllama-ios%2f&amp;title=Port%20the%20LLaMa%20Model%20on%20iOS&amp;summary=Port%20the%20LLaMa%20Model%20on%20iOS" target="_blank" rel="noopener" aria-label="Share on LinkedIn" class="social-btn linkedin">
          <li><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-linkedin" width="24" height="24" viewBox="0 0 352 352" fill="var(--color-primary)"><path d="M0,40v272c0,21.9,18.1,40,40,40h272c21.9,0,40-18.1,40-40V40c0-21.9-18.1-40-40-40H40C18.1,0,0,18.1,0,40z M312,32 c4.6,0,8,3.4,8,8v272c0,4.6-3.4,8-8,8H40c-4.6,0-8-3.4-8-8V40c0-4.6,3.4-8,8-8H312z M59.5,87c0,15.2,12.3,27.5,27.5,27.5 c15.2,0,27.5-12.3,27.5-27.5c0-15.2-12.3-27.5-27.5-27.5C71.8,59.5,59.5,71.8,59.5,87z M187,157h-1v-21h-45v152h47v-75 c0-19.8,3.9-39,28.5-39c24.2,0,24.5,22.4,24.5,40v74h47v-83.5c0-40.9-8.7-72-56.5-72C208.5,132.5,193.3,145.1,187,157z M64,288h47.5 V136H64V288z"/></svg></li>
        </a>
        
        
        
        <a href="mailto:?subject=ai-doge%20-%20Port%20the%20LLaMa%20Model%20on%20iOS.&amp;body=Port%20the%20LLaMa%20Model%20on%20iOS%2c%20by%20ai-doge%0aHow%20to%20Port%20the%20LLaMa%20Model%20to%20Run%20on%20iOS%20Devices%0a%0ahttps%3a%2f%2fai-doge.github.io%2fposts%2fllama-ios%2f%0a" target="_blank" class="social-btn email">
          <li><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-mail" width="24" height="24" viewBox="0 0 416 288" fill="var(--color-primary)"><path d="m0 16v256 16h16 384 16v-16-256-16h-16-384-16zm347 16-139 92.5-139-92.5zm-148 125.5 9 5.5 9-5.5 167-111.5v210h-352v-210z"/></svg></li>
        </a>
      </ul>
    </div>
  </section>
  
        

  
  

        
  <section>
    <h2>Read Next</h2>
    <div class="single-next-previous">
      
        <a class="previous" href="https://ai-doge.github.io/posts/port_image_gan/">&laquo; Implementing ImageGAN</a>
      
      
    </div>
  </section>

      
    </aside>
  </div>
</div>

    </main><footer>
  
  <div class="section footer">
    <p class="footer-copyright">&copy; 2023 &middot; 
      <a href="https://ai-doge.github.io/">ai-doge</a>
      
        <span>&middot; Built with <a href="https://github.com/wjh18/hugo-liftoff" target="_blank" rel="noopener">Hugo Liftoff</a> theme.</span>
      
    </p>
    
      <div class="footer-socials">
        
<div class="social-links">
  <ul class="social-icons">
    
    
    <li>
      <a href="https://twitter.com/aidogeshow" target="_blank" rel="noopener" aria-label="Visit Twitter profile" class="social-btn twitter">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-twitter" width="24" height="24" viewBox="0 0 384 312" fill="var(--color-primary)"><path d="m384 36.9c-14.1 6.3-29.3 10.5-45.2 12.4 16.3-9.7 28.8-25.2 34.6-43.6-15.2 9-32.1 15.6-50 19.1-14.4-15.2-34.9-24.8-57.5-24.8-43.5 0-78.8 35.3-78.8 78.8 0 6.2.7 12.2 2 17.9-65.5-3.3-123.5-34.6-162.4-82.3-6.7 11.6-10.6 25.2-10.6 39.6 0 27.3 13.9 51.4 35 65.6-12.9-.4-25.1-4-35.7-9.9v1c0 38.2 27.2 70 63.2 77.2-6.6 1.8-13.6 2.8-20.8 2.8-5.1 0-10-.5-14.8-1.4 10 31.3 39.1 54.1 73.6 54.7-27 21.1-60.9 33.7-97.8 33.7-6.4 0-12.6-.4-18.8-1.1 34.9 22.4 76.3 35.4 120.8 35.4 144.9 0 224.1-120 224.1-224.1 0-3.4-.1-6.8-.2-10.2 15.4-11.1 28.7-25 39.3-40.8z"/></svg>
      </a>
    </li>
    

    
    

    
    
    <li>
      <a href="https://github.com/ai-doge" target="_blank" rel="noopener" aria-label="Visit Github profile" class="social-btn github">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-github" width="24" height="24" viewBox="0 0 24 24" fill="var(--color-primary)"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
      </a>
    </li>
    

    
    

    
    

    
    
  </ul>
</div>

      </div>
    
  </div>
</footer>

  





  
  
  
    
    
  




  
  
    

<script src="https://ai-doge.github.io/main.min.js"></script>



  
</body>
</html>
